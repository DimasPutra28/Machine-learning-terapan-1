# -*- coding: utf-8 -*-
"""klasifikasi_MLT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jwvg2gNVW-3JSW8SWumNd3XEXWVbjG0A

## Import Library

### pada tahapan ini terdapat berbagai library yang dibutuhkan untuk mendukung identifikasi dataset dan pembuatan klasifikasi model
"""

# import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import learning_curve

"""## Load Data

### Tahapan ini terdapat memuat sebuah dataset klasifikasi yaitu dataset kinerja dari siswa dan menampilkan beberapa isian dari data
"""

# load data
data = pd.read_csv('Student_performance_data.csv')

# menampilkan data
data.head()

"""## Exploratory Data Analysis

### - Pada tahapan ini terdapat identifikasi data untuk mengetahui jumlah baris dan kolom, mengetahui ada atau tidaknya missing value, identifikasi kolom numerik dan menunjukkan korelasi antar atribut
### - Melakukan plot untuk mengetahui distribusi dari variabel target, dan plot distribusi untuk hubungan antara beberapa variabel
"""

# identifikasi data
data.info()

# indentifikasi jumlah baris dan kolom
print(f"Jumlah baris: {data.shape[0]}, Jumlah kolom: {data.shape[1]}")

# identifikasi missing value data
missing_values = data.isnull().sum()
missing_values[missing_values > 0]

print(f"jumlah data yang hilang: ", missing_values)

# analisis kolom dataset
data.describe(include="all")

# identifikasi kolom numerik
kolom_numerik = data.select_dtypes(include=['int64', 'float64']).columns
data[kolom_numerik].hist(figsize=(12, 8), bins=30, edgecolor="black")
plt.tight_layout()
plt.show()

# Hitung korelasi antar fitur numerik
matriks_korelasi = data.corr(numeric_only=True)

# Buat plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(matriks_korelasi, annot=True, fmt=".2f", cmap='coolwarm', center=0, linewidths=0.5)
plt.title("Heatmap Korelasi Antar Variabel Numerik", fontsize=14)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Visualisasi distribusi kelas target
plt.figure(figsize=(6, 4))
sns.countplot(data=data, x='GradeClass', palette='Set2')
plt.title("Distribusi Jumlah Siswa per GradeClass")
plt.xlabel("GradeClass")
plt.ylabel("Jumlah Siswa")
plt.tight_layout()
plt.show()

# Boxplot GPA berdasarkan GradeClass
plt.figure(figsize=(6, 4))
sns.boxplot(data=data, x='GradeClass', y='GPA')
plt.title("Distribusi GPA berdasarkan GradeClass")
plt.xlabel("GradeClass")
plt.ylabel("GPA")
plt.tight_layout()
plt.show()

# Boxplot Absences berdasarkan GradeClass
plt.figure(figsize=(6, 4))
sns.boxplot(data=data, x='GradeClass', y='Absences')
plt.title("Distribusi Absensi berdasarkan GradeClass")
plt.xlabel("GradeClass")
plt.ylabel("Absences")
plt.tight_layout()
plt.show()

# Scatter plot GPA vs Absences
plt.figure(figsize=(6, 4))
sns.scatterplot(data=data, x='Absences', y='GPA', hue='GradeClass', palette='tab10')
plt.title("Hubungan GPA dan Absences")
plt.xlabel("Absences")
plt.ylabel("GPA")
plt.tight_layout()
plt.show()

"""# Insight

- Terdapat hubungan relasi positif pada atribut Gradeclass dan Absences yaitu 0.73. - dan terdapat relasi negatif yaitu gradeclass dan GPA yaitu -.78 pada atribut GPA dan Absences yaitu -92
- Persebaran distribusi gradeclass paling banyak yaitu 4 sekitar 1200 lebih siswa, selain itu grade 0-3 relatif rendah diangka 0-400 siswa
- GradeClass 0 dan 1 memiliki nilai GPA yang lebih tinggi dan stabil, dengan median mendekati atau di atas 3.0.
- GradeClass 4 memiliki distribusi GPA paling rendah — banyak siswa dengan GPA < 2, dan beberapa di bawah 1.
- Semakin tinggi GradeClass (angka lebih besar), semakin rendah GPA siswa — sesuai harapan bahwa GradeClass 4 menunjukkan performa lebih buruk.
- GradeClass 0 dan 1 memiliki absensi lebih sedikit (median sekitar 5).
- GradeClass 4 memiliki median absensi tertinggi (~20), dan banyak outliers absensi tinggi.

# Data Preprocessing

### Pada tahapan ini terdapat cek data untuk ada atau tidaknya nilai kosong dan nilai duplikat. dan melakukan normalisasi pada dataset
"""

# cek nilai kosong
print("Nilai Kosong: ")
print(data.isnull().sum())

print("\n")

# cek nilai duplikat
print("Nilai Duplikat: ")
print(data.duplicated().sum())

# Buat instance MinMaxScaler
scaler = MinMaxScaler()

numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns.tolist()
numeric_columns.remove('GradeClass')

# Terapkan MinMaxScaler hanya ke kolom yang dipilih
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# Tampilkan hasil
data.head()

"""# Spliting data

### Pada tahapan ini terdapat pembagian data yang digunakan training dan testing sebanyak 80 dan 20
"""

# pembagian label atribut dan target untuk training
X = data.drop(columns=['GradeClass'])
y = data['GradeClass']

# pembagian data training dan testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""# modelling

### Pada Tahapan ini terdapat modelling dengan menggunakan algoritma random forrest
"""

# modelling menggunakan randomforrest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

"""# Evaluasi model

### pada tahapan ini terdapat menampilkan hasil akurasi model dan perhitungan skor akurasi baik itu presisi skor, recall, dan f1 score
"""

# Lakukan prediksi terhadap data test
y_pred = rf_model.predict(X_test)

# evaluasi skor
def perform_evaluation(estimator, X_test, y_test):
    predictions = estimator.predict(X_test)
    matrix = confusion_matrix(y_test, predictions)

    # Ambil nilai TP, FP, FN, TN hanya jika biner
    if matrix.shape == (2, 2):
        tn, fp, fn, tp = matrix.ravel()
    else:
        tn = fp = fn = tp = None  # Tidak relevan untuk multi-kelas

    evaluation_result = {
        'Confusion Matrix': matrix,
        'TP': tp,
        'FP': fp,
        'FN': fn,
        'TN': tn,
        'Accuracy Score': accuracy_score(y_test, predictions),
        'Precision Score': precision_score(y_test, predictions, average='weighted'),
        'Recall Score': recall_score(y_test, predictions, average='weighted'),
        'F1 Score': f1_score(y_test, predictions, average='weighted')
    }
    return evaluation_result

# Evaluasi model yang sudah dilatih
model_dict = {
    'Random Forest Classifier': rf_model
}

evaluation_summary = {}

for name, clf in model_dict.items():
    evaluation_summary[name] = perform_evaluation(clf, X_test, y_test)

# Buat ringkasan dalam bentuk DataFrame
report_df = pd.DataFrame([
    {
        'Model Name': key,
        'Accuracy': val['Accuracy Score'],
        'Precision': val['Precision Score'],
        'Recall': val['Recall Score'],
        'F1 Score': val['F1 Score']
    }
    for key, val in evaluation_summary.items()
])

# Cetak ringkasan
print(report_df)

"""# visualisasi akurasi model

### pada tahapan ini terdapat menampilkan hasil visualisasi confussion matrix, hasil model yang di training dan testing model randomforrest
"""

# Fungsi alternatif untuk memvisualisasikan confusion matrix
def visualize_conf_matrix(estimator, X_test, y_true, label="rf_model"):
    # Prediksi dari model
    predicted = estimator.predict(X_test)

    # Hitung confusion matrix
    conf_mat = confusion_matrix(y_true, predicted)

    # Buat plot heatmap
    plt.figure(figsize=(6,5))
    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='YlGnBu',
                xticklabels=np.unique(y_true),
                yticklabels=np.unique(y_true))
    plt.title(f'Confusion Matrix for {label}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

# Contoh penggunaan fungsi untuk beberapa model
visualize_conf_matrix(rf_model, X_test, y_test, "Random Forest Classifier")

def plot_learning_curve(estimator, X, y, title="Learning Curve", cv=5, scoring='accuracy'):
    train_sizes, train_scores, val_scores = learning_curve(
        estimator, X, y, cv=cv, scoring=scoring,
        train_sizes=np.linspace(0.1, 1.0, 10), random_state=42
    )

    train_mean = np.mean(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)

    train_std = np.std(train_scores, axis=1)
    val_std = np.std(val_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')
    plt.plot(train_sizes, val_mean, 'o-', color='green', label='Validation Score')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='green')

    plt.title(title)
    plt.xlabel("Training Set Size")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Contoh pemanggilan untuk Random Forest
plot_learning_curve(rf_model, X_train, y_train, title="Learning Curve - Random Forest", cv=5)

"""# Hyperparameter tunning menggunakan GridSearchCV

### Pada tahapan ini , dilakukan tunning menggunakan GridSearchCV untuk mengurangi terjadi overfitting, / underfitting, dan membantu performa model lebih baik
"""

# Parameter grid untuk Random Forest
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Inisialisasi model
rf_base = RandomForestClassifier(random_state=42)

# GridSearchCV
grid_search_rf = GridSearchCV(estimator=rf_base,
                               param_grid=param_grid,
                               cv=5,
                               scoring='f1_weighted',
                               verbose=1,
                               n_jobs=-1)

# Fit GridSearchCV
grid_search_rf.fit(X_train, y_train)

# Ambil model terbaik
best_rf_model = grid_search_rf.best_estimator_

# Evaluasi model terbaik
y_pred_best = best_rf_model.predict(X_test)

"""# Visualisasi hasil tunning

### Pada tahapan Terakhir terdapat evaluasi dan visualisasi hasil dari tunning model dari GridSearchCV
"""

print("Best Parameters:", grid_search_rf.best_params_)
print("\nClassification Report:\n", classification_report(y_test, y_pred_best))
print("Accuracy:", accuracy_score(y_test, y_pred_best))
print("Precision:", precision_score(y_test, y_pred_best, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_best, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_best, average='weighted'))

plot_learning_curve(best_rf_model, X_train, y_train, title="Learning Curve - Tuned Random Forest", scoring='f1_weighted')

"""# Insight evaluasi model

-  pada penggunaan model random forrest, menghasilkan akurasi skor 0.91 (sebelum tunning) pada saat setelah tunning tidak ada perubahan di skor 0.91
- rata rata perhitungan presisi, recall dan f1 score rata rata diangka 90% dan 91%
"""